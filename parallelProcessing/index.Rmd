---
title: "Parallel Processing with Caret"
author: "Brett Taylor"
date: "October 11, 2015"
output: html_document
---

 
I utilize several different methods to improve performance including the parallel computing capabilities that have been developed in the Revolutions analytics version of R.  Below is a table that shows the difference in execution on a MacBook Pro which has 8 logical cores when parallel processing is utilized.  This has a large impact on the ability to test and create models that utilize a large amount of compute capabilities.   My next attempt will be parallel processsing across multiple machines. 

```{r measurePerformance, echo=FALSE, message=FALSE}
library(dplyr)
library(knitr)
library(caret)
performanceMetrics <- read.csv("../perform.log",sep = "\t")
performanceMetrics <- performanceMetrics%>%filter(quickRun == FALSE)
performanceMetrics <- performanceMetrics%>%select(-quickRun)
performanceMetrics <- as.data.frame(performanceMetrics)
performanceMetrics$user <- performanceMetrics$user/60
performanceMetrics$system <- performanceMetrics$system / 60
performanceMetrics$elapsed <- performanceMetrics$elapsed / 60

kable(performanceMetrics,digits = 1,caption = "Compute Performance Metrics - in Minutes")
```

#Parallel Processing
The code execution performance is very time consuming and resource intensive so I adopted the parallel processing model that is embedded in the caret package.  Parallel processing will work when you utilize the forEach() method in your code, and luckily this will work.  The functions that build the models written above allow the passing of a parameter _runInParallel()_ and _cores_ that enables the use of the the library doMC which on an Operating System that supports fork() (OS/X , Linux, Unix) will take advantage of the local processors and the multi-core chips.    I worked through many problems and discovered that this code may not be run within the RStudio IDE.   You must execute it from the terminal command line.   

__>RScript runModels.R__

```{r tidy=TRUE,eval=FALSE}
#runModels.R
source("buildData.R")
fast = FALSE
buildData(quickRun=fast)
message("load buildModelGbm.R")
source("buildModelGbm.R")
training <- read.csv("./data/training.csv")
message("run buildGbm()")
gmbFit <- buildGbm(quickRun =fast,runInParallel=TRUE,cores=4,data=training)
source("buildModelSvm.R")
svmFit <- buildSvm(quickRun =fast,runInParallel=TRUE,cores=4,data=training)
source("buildModelRfm.R")
rfmFit <- buildRfm(quickRun =fast,runInParallel=TRUE,cores=4,data=training)

``` 

_>RScript runModels.R_

The advantage of this is that you can reduce the time to train the model by over 1/3 of the time that serial computation takes in R if you utilize 4 to 5 cores to process.
 